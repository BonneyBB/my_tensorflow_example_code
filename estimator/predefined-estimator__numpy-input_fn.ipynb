{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [Reference](https://tensorflow.google.cn/get_started/estimator#construct_a_deep_neural_network_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import os\n",
    "from urllib.request import urlopen\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load iris data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "IRIS_TRAINING = \"iris_training.csv\"\n",
    "IRIS_TRAINING_URL = \"http://download.tensorflow.org/data/iris_training.csv\"\n",
    "\n",
    "IRIS_TEST = \"iris_test.csv\"\n",
    "IRIS_TEST_URL = \"http://download.tensorflow.org/data/iris_test.csv\"\n",
    "\n",
    "# if not os.path.exists(IRIS_TRAINING):\n",
    "raw = urlopen(IRIS_TRAINING_URL).read().decode()\n",
    "with open(IRIS_TRAINING,'w') as f:\n",
    "    f.write(raw)\n",
    "\n",
    "# if not os.path.exists(IRIS_TEST):\n",
    "raw = urlopen(IRIS_TEST_URL).read().decode()\n",
    "with open(IRIS_TEST,'w') as f:\n",
    "    f.write(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load datasets.\n",
    "train_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TRAINING,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)\n",
    "test_set = tf.contrib.learn.datasets.base.load_csv_with_header(\n",
    "    filename=IRIS_TEST,\n",
    "    target_dtype=np.int,\n",
    "    features_dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensorflow.contrib.learn.python.learn.datasets.base.Dataset,\n",
       " tensorflow.contrib.learn.python.learn.datasets.base.Dataset)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set),type(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, (120, 4))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_set.data), train_set.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a Deep Neural Network Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.estimator offers a variety of predefined models, called Estimators, which you can use \"out of the box\" to run training and evaluation operations on your data. Here, you'll configure a Deep Neural Network Classifier model to fit the Iris data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define a feature column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a feature column define the data type for the data in data set.\n",
    "there are 3 feature in data, so must set the shape to [4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Specify that all features have real-value data\n",
    "feature_columns = [tf.feature_column.numeric_column(\"x\", shape=[4])]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then use the pre-defined model to fit the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_keep_checkpoint_max': 5, '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_model_dir': '/tmp/iris_model', '_save_summary_steps': 100, '_session_config': None, '_tf_random_seed': 1, '_save_checkpoints_secs': 600, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "# Build 3 layer DNN with 10, 20, 10 units respectively.\n",
    "classifier = tf.estimator.DNNClassifier(feature_columns=feature_columns,\n",
    "                                        hidden_units=[10, 20, 10],\n",
    "                                        n_classes=3,\n",
    "                                        model_dir=\"/tmp/iris_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Describe the training input pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tf.estimator use the input_fn to feed the data. Here we user the tf.estimator.inputs_numpy_input_fn to define the input pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the training inputs\n",
    "train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(train_set.data)},\n",
    "    y=np.array(train_set.target),\n",
    "    num_epochs=None,\n",
    "    shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the DNNClassifier to the Iris Training Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The we can feed the input_fn to the model and start training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:step = 1, loss = 255.437\n",
      "INFO:tensorflow:Saving checkpoints for 10 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 91.04.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f2b495decf8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn, steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The state of the model is saved in the classifer, so you can continue training later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-20\n",
      "INFO:tensorflow:Saving checkpoints for 21 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:step = 21, loss = 49.3807\n",
      "INFO:tensorflow:Saving checkpoints for 30 into /tmp/iris_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 41.7445.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.dnn.DNNClassifier at 0x7f2b495decf8>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.train(input_fn=train_input_fn,steps=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate Model Accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You've trained your DNNClassifier model on the Iris training data; now, you can check its accuracy on the Iris test data using the evaluate method. Like train, evaluate takes an input function that builds its input pipeline. evaluate returns a dicts with the evaluation results. The following code passes the Iris test data—test_set.data and test_set.target—to evaluate and prints the accuracy from the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Starting evaluation at 2017-09-08-01:28:38\n",
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-2000\n",
      "INFO:tensorflow:Finished evaluation at 2017-09-08-01:28:38\n",
      "INFO:tensorflow:Saving dict for global step 2000: accuracy = 0.966667, average_loss = 0.0570463, global_step = 2000, loss = 1.71139\n"
     ]
    }
   ],
   "source": [
    "# Define the test inputs\n",
    "test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(test_set.data)},\n",
    "    y=np.array(test_set.target),\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "# Evaluate accuracy.\n",
    "accuracy_score = classifier.evaluate(input_fn=test_input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.96666664,\n",
       " 'average_loss': 0.057046309,\n",
       " 'global_step': 2000,\n",
       " 'loss': 1.7113893}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classify New Samples\n",
    "\n",
    "Use the estimator's predict() method to classify new samples. For example, say you have these two new flower samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from /tmp/iris_model/model.ckpt-2000\n",
      "New Samples, Class Predictions:    [array([b'1'], dtype=object), array([b'2'], dtype=object)]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Classify two new flower samples.\n",
    "new_samples = np.array(\n",
    "    [[6.4, 3.2, 4.5, 1.5],\n",
    "     [5.8, 3.1, 5.0, 1.7]], dtype=np.float32)\n",
    "predict_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": new_samples},\n",
    "    num_epochs=1,\n",
    "    shuffle=False)\n",
    "\n",
    "predictions = list(classifier.predict(input_fn=predict_input_fn))\n",
    "predicted_classes = [p[\"classes\"] for p in predictions]\n",
    "\n",
    "print(\n",
    "    \"New Samples, Class Predictions:    {}\\n\"\n",
    "    .format(predicted_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'class_ids': array([1]),\n",
       "  'classes': array([b'1'], dtype=object),\n",
       "  'logits': array([-5.15059233,  4.87604856, -3.81199336], dtype=float32),\n",
       "  'probabilities': array([  4.41970005e-05,   9.99787271e-01,   1.68553976e-04], dtype=float32)},\n",
       " {'class_ids': array([2]),\n",
       "  'classes': array([b'2'], dtype=object),\n",
       "  'logits': array([-9.74863625,  0.85466111,  2.27391148], dtype=float32),\n",
       "  'probabilities': array([  4.83711892e-06,   1.94778189e-01,   8.05216968e-01], dtype=float32)}]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
