{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a skeleton of basic input function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_input_fn():\n",
    "\n",
    "    # Preprocess your data here...\n",
    "\n",
    "    # ...then return 1) a mapping of feature columns to Tensors with\n",
    "    # the corresponding feature data, and 2) a Tensor containing labels\n",
    "    return feature_cols, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function of input function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input function must return\n",
    "\n",
    "* feature columns\n",
    "    a dict contain key/value paires that map feature column name to `Tensors` containing the corresponding `feature data`.\n",
    "* labels\n",
    "a `Tensor` contain your label data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting feature data to tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we said above, **feature column** need **Tensor** that contains feature data. so we need convert our data into **Tensor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### python array, numpy array, dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if you data is python array, numpy array, dataframe, you can use following data to convert to Tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "import numpy as np\n",
    "# numpy input_fn.\n",
    "\n",
    "my_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "    x={\"x\": np.array(x_data)},\n",
    "    y=np.array(y_data),\n",
    "    ...)\n",
    "import pandas as pd\n",
    "\n",
    "# pandas input_fn.\n",
    "\n",
    "my_input_fn = tf.estimator.inputs.pandas_input_fn(\n",
    "    x=pd.DataFrame({\"x\": x_data}),\n",
    "    y=pd.Series(y_data),\n",
    "    ...)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can check this [official tutorial](https://tensorflow.google.cn/get_started/estimator#construct_a_deep_neural_network_classifier) for a example and run it to get a feeling of it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "these 2 function have other paramter for you  to customize the input function. check it out at official documetns:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a list:\n",
    "\n",
    "* batch_size: int, size of batches to return.\n",
    "\n",
    "* num_epochs: int, number of epochs to iterate over data. If not None, read attempts that would exceed this value will raise OutOfRangeError.\n",
    "\n",
    "* shuffle: bool, whether to read the records in random order.\n",
    "\n",
    "* queue_capacity: int, size of the read queue. If None, it will be set roughly to the size of x.\n",
    "\n",
    "* num_threads: Integer, number of threads used for reading and enqueueing. In order to have predicted and repeatable order of reading and enqueueing, such as in prediction and evaluation mode, num_threads should be 1.\n",
    "\n",
    "* target_column: str, name to give the target column y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trick"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use ```functools.partial``` to wrap your function, so you don't need define separatly function to each type of task(training, validation, prediction) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "my_input_fn(data_set):\n",
    "    # balalalal\n",
    "\n",
    "    # ...then return 1) a mapping of feature columns to Tensors with\n",
    "    # the corresponding feature data, and 2) a Tensor containing labels\n",
    "    return feature_cols, labels\n",
    "```\n",
    "---\n",
    "```\n",
    "classifier.train(\n",
    "    input_fn=functools.partial(my_input_fn, data_set=training_set),\n",
    "    steps=2000)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
